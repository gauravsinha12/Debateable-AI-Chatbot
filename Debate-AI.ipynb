{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN5VzFg10wVqj3UKSr2jrwG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"af6b0bdd272a4ba99e33347185431b8a":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_120a770dde8c427d887bf2cdb3e0db75","IPY_MODEL_f5f8cab6cfb843f1a317a33c4d54c081","IPY_MODEL_d7ec7a14300b4a648e3dc29c4ea2260a","IPY_MODEL_5bb640e8907644e0a9e10e832986a0ed"],"layout":"IPY_MODEL_4b395c5f02df4d68afb79bd1fc817d3b"}},"c06e13f00d194124813c4611d9d4e0aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86ba1abe788b4e46909776024247927a","placeholder":"​","style":"IPY_MODEL_3d07b639cab2471da5f88ed941154694","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"26cd2f39b2834b39b087a764d3a77def":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_31dcf0be7da34924ba8c6ad75721429a","placeholder":"​","style":"IPY_MODEL_bcf0b1c129b5493b8d42569786f57019","value":""}},"e4356e5f0ada420f9795317ea9a98f4b":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_f62d8e09b0d640d091bccb8723239695","style":"IPY_MODEL_c823d480c25b4e1e92cc288c72824627","value":true}},"325de1de3d514d4e9b21c314aa20372a":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_561266f45ec946a4b347cb668e0ed046","style":"IPY_MODEL_e0933addb0f647fe8131f4b0dc32f7c1","tooltip":""}},"45eace55ba374888afa26f48c125afc4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac8be3fbc51d49b2a015fb9f6213402b","placeholder":"​","style":"IPY_MODEL_1b4d0e8300eb4973a5053daff988c967","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"4b395c5f02df4d68afb79bd1fc817d3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"86ba1abe788b4e46909776024247927a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d07b639cab2471da5f88ed941154694":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31dcf0be7da34924ba8c6ad75721429a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcf0b1c129b5493b8d42569786f57019":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f62d8e09b0d640d091bccb8723239695":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c823d480c25b4e1e92cc288c72824627":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"561266f45ec946a4b347cb668e0ed046":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0933addb0f647fe8131f4b0dc32f7c1":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"ac8be3fbc51d49b2a015fb9f6213402b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b4d0e8300eb4973a5053daff988c967":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0de19b2139b742d387f63e8fe4460a75":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1368d5dc93c941299929e66b697a96d7","placeholder":"​","style":"IPY_MODEL_571a018421354777aac706a1ca9725a7","value":"Connecting..."}},"1368d5dc93c941299929e66b697a96d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"571a018421354777aac706a1ca9725a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"120a770dde8c427d887bf2cdb3e0db75":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91481a5226b648b799cfaf28ba5b6382","placeholder":"​","style":"IPY_MODEL_f784ffdf19c646b3b8be3c7e8154992b","value":"Token is valid (permission: write)."}},"f5f8cab6cfb843f1a317a33c4d54c081":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf63fa408940451199f7a8a174ece13d","placeholder":"​","style":"IPY_MODEL_31e9c2525d3a49a5b85786eb20dc8739","value":"Your token has been saved in your configured git credential helpers (store)."}},"d7ec7a14300b4a648e3dc29c4ea2260a":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30aed4e587f54ba588780671e249b0bd","placeholder":"​","style":"IPY_MODEL_efb449777270450cba6e4acecffdcb52","value":"Your token has been saved to /root/.cache/huggingface/token"}},"5bb640e8907644e0a9e10e832986a0ed":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b8049649c6e474ca4aba2b26e46e863","placeholder":"​","style":"IPY_MODEL_f5f2aba6c33541daa255d2895c5ceabf","value":"Login successful"}},"91481a5226b648b799cfaf28ba5b6382":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f784ffdf19c646b3b8be3c7e8154992b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf63fa408940451199f7a8a174ece13d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31e9c2525d3a49a5b85786eb20dc8739":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30aed4e587f54ba588780671e249b0bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efb449777270450cba6e4acecffdcb52":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b8049649c6e474ca4aba2b26e46e863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5f2aba6c33541daa255d2895c5ceabf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13c25fc4cfe541efb3b34cb7fb92bd46":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34244d974e3048b4a9eea636b82fe300","IPY_MODEL_e0784e5d7b094466afad7ebc5f99fbcc","IPY_MODEL_0ce9a6b0f39740979891019a3f611139"],"layout":"IPY_MODEL_61fbb9b0088a48ed88b7550ab7e6da46"}},"34244d974e3048b4a9eea636b82fe300":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36b68afe29764a04a07df6fcc3b4fc51","placeholder":"​","style":"IPY_MODEL_8aedccbdc0fe47de89c9d38f44618c10","value":"Map: 100%"}},"e0784e5d7b094466afad7ebc5f99fbcc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_54d40328ef114f75adcc50ab22db2c74","max":321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a9ea7bc83fa4cef96e5be71c82f12c4","value":321}},"0ce9a6b0f39740979891019a3f611139":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_217e3e9541c54e08910adf3a0343cbd9","placeholder":"​","style":"IPY_MODEL_b5e5adcfe6eb4e03beeab5baa7dd332d","value":" 321/321 [00:01&lt;00:00, 292.18 examples/s]"}},"61fbb9b0088a48ed88b7550ab7e6da46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36b68afe29764a04a07df6fcc3b4fc51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aedccbdc0fe47de89c9d38f44618c10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54d40328ef114f75adcc50ab22db2c74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a9ea7bc83fa4cef96e5be71c82f12c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"217e3e9541c54e08910adf3a0343cbd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5e5adcfe6eb4e03beeab5baa7dd332d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["! pip install datasets transformers trl peft accelerate bitsandbytes auto-gptq optimum"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rhS7cod9xAC","executionInfo":{"status":"ok","timestamp":1698406758954,"user_tz":-330,"elapsed":29550,"user":{"displayName":"Gaurav Sinha","userId":"06135974110330871426"}},"outputId":"e94f5b2d-2e16-476b-8a33-08bc9bcf022d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trl\n","  Downloading trl-0.7.2-py3-none-any.whl (124 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.0/124.0 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting peft\n","  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate\n","  Downloading accelerate-0.24.0-py3-none-any.whl (260 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting bitsandbytes\n","  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting auto-gptq\n","  Downloading auto_gptq-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting optimum\n","  Downloading optimum-1.13.2.tar.gz (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.0/301.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n","Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.1.0+cu118)\n","Collecting tyro>=0.5.7 (from trl)\n","  Downloading tyro-0.5.10-py3-none-any.whl (94 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Collecting rouge (from auto-gptq)\n","  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Collecting coloredlogs (from optimum)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.12)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.1.0)\n","Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers) (3.20.3)\n","Collecting docstring-parser>=0.14.1 (from tyro>=0.5.7->trl)\n","  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.7->trl) (13.6.0)\n","Collecting shtab>=1.5.6 (from tyro>=0.5.7->trl)\n","  Downloading shtab-1.6.4-py3-none-any.whl (13 kB)\n","Collecting humanfriendly>=9.1 (from coloredlogs->optimum)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum) (1.3.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.7->trl) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.7->trl) (2.16.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.7->trl) (0.1.2)\n","Building wheels for collected packages: optimum\n","  Building wheel for optimum (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for optimum: filename=optimum-1.13.2-py3-none-any.whl size=395599 sha256=faae208c34c941b38d66f22d318669a3d651de2b33f2a03836a5fc068e13499f\n","  Stored in directory: /root/.cache/pip/wheels/6e/b7/2c/79405d98f0943373d8546daeae25a3d377f7659ca0cbe48699\n","Successfully built optimum\n","Installing collected packages: sentencepiece, bitsandbytes, shtab, safetensors, rouge, humanfriendly, docstring-parser, dill, multiprocess, huggingface-hub, coloredlogs, tyro, tokenizers, accelerate, transformers, datasets, trl, peft, optimum, auto-gptq\n","Successfully installed accelerate-0.24.0 auto-gptq-0.4.2 bitsandbytes-0.41.1 coloredlogs-15.0.1 datasets-2.14.6 dill-0.3.7 docstring-parser-0.15 huggingface-hub-0.17.3 humanfriendly-10.0 multiprocess-0.70.15 optimum-1.13.2 peft-0.5.0 rouge-1.0.1 safetensors-0.4.0 sentencepiece-0.1.99 shtab-1.6.4 tokenizers-0.14.1 transformers-4.34.1 trl-0.7.2 tyro-0.5.10\n"]}]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["af6b0bdd272a4ba99e33347185431b8a","c06e13f00d194124813c4611d9d4e0aa","26cd2f39b2834b39b087a764d3a77def","e4356e5f0ada420f9795317ea9a98f4b","325de1de3d514d4e9b21c314aa20372a","45eace55ba374888afa26f48c125afc4","4b395c5f02df4d68afb79bd1fc817d3b","86ba1abe788b4e46909776024247927a","3d07b639cab2471da5f88ed941154694","31dcf0be7da34924ba8c6ad75721429a","bcf0b1c129b5493b8d42569786f57019","f62d8e09b0d640d091bccb8723239695","c823d480c25b4e1e92cc288c72824627","561266f45ec946a4b347cb668e0ed046","e0933addb0f647fe8131f4b0dc32f7c1","ac8be3fbc51d49b2a015fb9f6213402b","1b4d0e8300eb4973a5053daff988c967","0de19b2139b742d387f63e8fe4460a75","1368d5dc93c941299929e66b697a96d7","571a018421354777aac706a1ca9725a7","120a770dde8c427d887bf2cdb3e0db75","f5f8cab6cfb843f1a317a33c4d54c081","d7ec7a14300b4a648e3dc29c4ea2260a","5bb640e8907644e0a9e10e832986a0ed","91481a5226b648b799cfaf28ba5b6382","f784ffdf19c646b3b8be3c7e8154992b","cf63fa408940451199f7a8a174ece13d","31e9c2525d3a49a5b85786eb20dc8739","30aed4e587f54ba588780671e249b0bd","efb449777270450cba6e4acecffdcb52","4b8049649c6e474ca4aba2b26e46e863","f5f2aba6c33541daa255d2895c5ceabf"]},"id":"dp3c7cyX_H6K","executionInfo":{"status":"ok","timestamp":1698407683886,"user_tz":-330,"elapsed":810,"user":{"displayName":"Gaurav Sinha","userId":"06135974110330871426"}},"outputId":"71c0d014-97aa-4d03-cf1b-d126092c057b"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af6b0bdd272a4ba99e33347185431b8a"}},"metadata":{}}]},{"cell_type":"code","source":["import torch\n","from datasets import load_dataset, Dataset\n","from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n","from transformers import AutoModelForCausalLM, AutoTokenizer, GPTQConfig, TrainingArguments\n","from trl import SFTTrainer"],"metadata":{"id":"2T2DjAUgBbz2","executionInfo":{"status":"ok","timestamp":1698406783193,"user_tz":-330,"elapsed":15126,"user":{"displayName":"Gaurav Sinha","userId":"06135974110330871426"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class Config:\n","    MODEL_ID = \"TheBloke/zephyr-7B-alpha-GPTQ\"\n","    DATASET_ID = \"gaurav16/temples_dataset\"  # Update to your dataset ID\n","    CONTEXT_FIELD = \"\"  # Update to the context field in your dataset\n","    INSTRUCTION_FIELD = \"Prompts\"  # Update to the prompts field in your dataset\n","    TARGET_FIELD = \"contexts\"\n","    BITS = 4\n","    DISABLE_EXLLAMA = True\n","    DEVICE_MAP = \"auto\"\n","    USE_CACHE = False\n","    LORA_R = 16\n","    LORA_ALPHA = 16\n","    LORA_DROPOUT = 0.05\n","    BIAS = \"none\"\n","    TARGET_MODULES = [\"q_proj\", \"v_proj\"]\n","    TASK_TYPE = \"CAUSAL_LM\"\n","    OUTPUT_DIR = \"zephyr-support-chatbot\"\n","    BATCH_SIZE = 8\n","    GRAD_ACCUMULATION_STEPS = 1\n","    OPTIMIZER = \"paged_adamw_32bit\"\n","    LR = 2e-4\n","    LR_SCHEDULER = \"cosine\"\n","    LOGGING_STEPS = 50\n","    SAVE_STRATEGY = \"epoch\"\n","    NUM_TRAIN_EPOCHS = 1\n","    MAX_STEPS = 250\n","    FP16 = True\n","    PUSH_TO_HUB = True\n","    DATASET_TEXT_FIELD = \"text\"  # Update to the appropriate text field in your dataset\n","    MAX_SEQ_LENGTH = 512\n","    PACKING = False\n"],"metadata":{"id":"BlZIuM2nEpdh","executionInfo":{"status":"ok","timestamp":1698407250105,"user_tz":-330,"elapsed":586,"user":{"displayName":"Gaurav Sinha","userId":"06135974110330871426"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class ZephyrTrainer:\n","\n","    def __init__(self):\n","\n","        '''\n","        A Trainer used to train the Zephyr 7B model which beats Llama2-70b-chat model for your custom usecase\n","\n","        Initialized:\n","        config: Parameters required for the trainer to create and process dataset, train and save model finally\n","        tokenizer: Tokenizer required in training loop\n","        '''\n","\n","        self.config = Config()\n","        self.tokenizer = AutoTokenizer.from_pretrained(self.config.MODEL_ID)\n","        self.tokenizer.pad_token = self.tokenizer.eos_token\n","\n","    def process_data_sample(self, example):\n","\n","        '''\n","        Helper function to process the dataset sample by adding prompt and clean if necessary.\n","\n","        Args:\n","        example: Data sample\n","\n","        Returns:\n","        processed_example: Data sample post processing\n","        '''\n","\n","        processed_example = \"<|system|>\\n You are a Debateable AI chatbot who engages in debates on the topic of the destruction of temples in India. As an unbiased and professional AI, you have your own views and opinions, and you strongly stand against the destruction of temples. You are ready to debate with anyone and present your points with conviction and evidence to support your stance.</s>\\n<|user|>\\n\" + example[self.config.INSTRUCTION_FIELD] + \"</s>\\n<|Debater|>\\n\" + example[self.config.TARGET_FIELD]\n","\n","        return processed_example\n","\n","    def create_dataset(self):\n","\n","        '''\n","        Downloads and processes the dataset\n","\n","        Returns:\n","        processed_data: Training ready processed dataset\n","        '''\n","\n","        data = load_dataset(self.config.DATASET_ID, split=\"train\")\n","\n","        print(\"\\n====================================================================\\n\")\n","        print(\"\\t\\t\\tDOWNLOADED DATASET\")\n","        print(\"\\n====================================================================\\n\")\n","\n","        df = data.to_pandas()\n","        df[self.config.DATASET_TEXT_FIELD] = df[[self.config.INSTRUCTION_FIELD, self.config.TARGET_FIELD]].apply(lambda x: self.process_data_sample(x), axis=1)\n","\n","        print(\"\\n====================================================================\\n\")\n","        print(\"\\t\\t\\tPROCESSED DATASET\")\n","        print(df.iloc[0])\n","        print(\"\\n====================================================================\\n\")\n","\n","        processed_data = Dataset.from_pandas(df[[self.config.DATASET_TEXT_FIELD]])\n","        return processed_data\n","\n","    def prepare_model(self):\n","\n","        '''\n","        Prepares model for finetuning by quantizing it and attaching lora modules to the model\n","\n","        Returns:\n","        model - Model ready for finetuning\n","        peft_config - LoRA Adapter config\n","        '''\n","\n","        bnb_config = GPTQConfig(\n","                                    bits=self.config.BITS,\n","                                    disable_exllama=self.config.DISABLE_EXLLAMA,\n","                                    tokenizer=self.tokenizer\n","                                )\n","\n","        model = AutoModelForCausalLM.from_pretrained(\n","                                                        self.config.MODEL_ID,\n","                                                        quantization_config=bnb_config,\n","                                                        device_map=self.config.DEVICE_MAP\n","                                                    )\n","\n","        print(\"\\n====================================================================\\n\")\n","        print(\"\\t\\t\\tDOWNLOADED MODEL\")\n","        print(model)\n","        print(\"\\n====================================================================\\n\")\n","\n","        model.config.use_cache=self.config.USE_CACHE\n","        model.config.pretraining_tp=1\n","        model.gradient_checkpointing_enable()\n","        model = prepare_model_for_kbit_training(model)\n","\n","        print(\"\\n====================================================================\\n\")\n","        print(\"\\t\\t\\tMODEL CONFIG UPDATED\")\n","        print(\"\\n====================================================================\\n\")\n","\n","        peft_config = LoraConfig(\n","                                    r=self.config.LORA_R,\n","                                    lora_alpha=self.config.LORA_ALPHA,\n","                                    lora_dropout=self.config.LORA_DROPOUT,\n","                                    bias=self.config.BIAS,\n","                                    task_type=self.config.TASK_TYPE,\n","                                    target_modules=self.config.TARGET_MODULES\n","                                )\n","\n","        model = get_peft_model(model, peft_config)\n","\n","        print(\"\\n====================================================================\\n\")\n","        print(\"\\t\\t\\tPREPARED MODEL FOR FINETUNING\")\n","        print(model)\n","        print(\"\\n====================================================================\\n\")\n","\n","        return model, peft_config\n","\n","    def set_training_arguments(self):\n","\n","        '''\n","        Sets the arguments for the training loop in TrainingArguments class\n","        '''\n","\n","        training_arguments = TrainingArguments(\n","                                                output_dir=self.config.OUTPUT_DIR,\n","                                                per_device_train_batch_size=self.config.BATCH_SIZE,\n","                                                gradient_accumulation_steps=self.config.GRAD_ACCUMULATION_STEPS,\n","                                                optim=self.config.OPTIMIZER,\n","                                                learning_rate=self.config.LR,\n","                                                lr_scheduler_type=self.config.LR_SCHEDULER,\n","                                                save_strategy=self.config.SAVE_STRATEGY,\n","                                                logging_steps=self.config.LOGGING_STEPS,\n","                                                num_train_epochs=self.config.NUM_TRAIN_EPOCHS,\n","                                                max_steps=self.config.MAX_STEPS,\n","                                                fp16=self.config.FP16,\n","                                                push_to_hub=self.config.PUSH_TO_HUB\n","                                            )\n","\n","        return training_arguments\n","\n","    def train(self):\n","\n","        '''\n","        Trains the model on the specified dataset in config\n","        '''\n","\n","        data = self.create_dataset()\n","        model, peft_config = self.prepare_model()\n","        training_args = self.set_training_arguments()\n","\n","        print(\"\\n====================================================================\\n\")\n","        print(\"\\t\\t\\tPREPARED FOR FINETUNING\")\n","        print(\"\\n====================================================================\\n\")\n","\n","        trainer = SFTTrainer(\n","                                model=model,\n","                                train_dataset=data,\n","                                peft_config=peft_config,\n","                                dataset_text_field=self.config.DATASET_TEXT_FIELD,\n","                                args=training_args,\n","                                tokenizer=self.tokenizer,\n","                                packing=self.config.PACKING,\n","                                max_seq_length=self.config.MAX_SEQ_LENGTH\n","                            )\n","        trainer.train()\n","\n","        print(\"\\n====================================================================\\n\")\n","        print(\"\\t\\t\\tFINETUNING COMPLETED\")\n","        print(\"\\n====================================================================\\n\")\n","\n","        trainer.push_to_hub()"],"metadata":{"id":"OqhM_hWrtwXl","executionInfo":{"status":"ok","timestamp":1698407254864,"user_tz":-330,"elapsed":662,"user":{"displayName":"Gaurav Sinha","userId":"06135974110330871426"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    zephyr_trainer = ZephyrTrainer()\n","    zephyr_trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["13c25fc4cfe541efb3b34cb7fb92bd46","34244d974e3048b4a9eea636b82fe300","e0784e5d7b094466afad7ebc5f99fbcc","0ce9a6b0f39740979891019a3f611139","61fbb9b0088a48ed88b7550ab7e6da46","36b68afe29764a04a07df6fcc3b4fc51","8aedccbdc0fe47de89c9d38f44618c10","54d40328ef114f75adcc50ab22db2c74","2a9ea7bc83fa4cef96e5be71c82f12c4","217e3e9541c54e08910adf3a0343cbd9","b5e5adcfe6eb4e03beeab5baa7dd332d"]},"id":"phERh2ZW8OHK","outputId":"4e66aab2-e2b2-406e-85c9-66b0aaa46ebc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","====================================================================\n","\n","\t\t\tDOWNLOADED DATASET\n","\n","====================================================================\n","\n","\n","====================================================================\n","\n","\t\t\tPROCESSED DATASET\n","Unnamed: 0                                                    0\n","Prompts       \\n\\nPrompt: \"The destruction of Hindu temples ...\n","contexts      : \\n\\n \\nThe movement for the restoration of t...\n","text          <|system|>\\n You are a Debateable AI chatbot w...\n","Name: 0, dtype: object\n","\n","====================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. disable_exllama, use_cuda_fp16, max_input_length) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n"]},{"output_type":"stream","name":"stdout","text":["\n","====================================================================\n","\n","\t\t\tDOWNLOADED MODEL\n","MistralForCausalLM(\n","  (model): MistralModel(\n","    (embed_tokens): Embedding(32000, 4096, padding_idx=2)\n","    (layers): ModuleList(\n","      (0-31): 32 x MistralDecoderLayer(\n","        (self_attn): MistralAttention(\n","          (rotary_emb): MistralRotaryEmbedding()\n","          (k_proj): QuantLinear()\n","          (o_proj): QuantLinear()\n","          (q_proj): QuantLinear()\n","          (v_proj): QuantLinear()\n","        )\n","        (mlp): MistralMLP(\n","          (act_fn): SiLUActivation()\n","          (down_proj): QuantLinear()\n","          (gate_proj): QuantLinear()\n","          (up_proj): QuantLinear()\n","        )\n","        (input_layernorm): MistralRMSNorm()\n","        (post_attention_layernorm): MistralRMSNorm()\n","      )\n","    )\n","    (norm): MistralRMSNorm()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",")\n","\n","====================================================================\n","\n","\n","====================================================================\n","\n","\t\t\tMODEL CONFIG UPDATED\n","\n","====================================================================\n","\n","\n","====================================================================\n","\n","\t\t\tPREPARED MODEL FOR FINETUNING\n","PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): MistralForCausalLM(\n","      (model): MistralModel(\n","        (embed_tokens): Embedding(32000, 4096, padding_idx=2)\n","        (layers): ModuleList(\n","          (0-31): 32 x MistralDecoderLayer(\n","            (self_attn): MistralAttention(\n","              (rotary_emb): MistralRotaryEmbedding()\n","              (k_proj): QuantLinear()\n","              (o_proj): QuantLinear()\n","              (q_proj): QuantLinear(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (quant_linear_module): QuantLinear()\n","              )\n","              (v_proj): QuantLinear(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (quant_linear_module): QuantLinear()\n","              )\n","            )\n","            (mlp): MistralMLP(\n","              (act_fn): SiLUActivation()\n","              (down_proj): QuantLinear()\n","              (gate_proj): QuantLinear()\n","              (up_proj): QuantLinear()\n","            )\n","            (input_layernorm): MistralRMSNorm()\n","            (post_attention_layernorm): MistralRMSNorm()\n","          )\n","        )\n","        (norm): MistralRMSNorm()\n","      )\n","      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n","    )\n","  )\n",")\n","\n","====================================================================\n","\n","\n","====================================================================\n","\n","\t\t\tPREPARED FOR FINETUNING\n","\n","====================================================================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/321 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13c25fc4cfe541efb3b34cb7fb92bd46"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:214: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n","  warnings.warn(\n","You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='57' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 57/250 12:34 < 44:08, 0.07 it/s, Epoch 1.37/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>2.194400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]}]}]}